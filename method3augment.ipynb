{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"/Users/keisipani/Desktop/BscAI/ML/ML/thyroidDF.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "groups = df.groupby(\"target\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_numeric_noise_by_group(df, group_col, numeric_cols, noise_factor=0.1):\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise to numeric columns while preserving group-based distributions.\n",
    "    \n",
    "    - noise_factor: Determines the percentage of the standard deviation used as noise.\n",
    "    - Each value will randomly ADD or SUBTRACT a sampled portion of the standard deviation.\n",
    "    \"\"\"\n",
    "    noisy_dfs = []\n",
    "    \n",
    "    for _, group in df.groupby(group_col):\n",
    "        group_noisy = group.copy()\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            # Calculate standard deviation for this group/column\n",
    "            std_dev = group[col].std()\n",
    "            \n",
    "            # Generate random signs (-1 or 1) for each row\n",
    "            signs = np.random.choice([-1, 1], size=len(group))\n",
    "            \n",
    "            # Generate noise with the same standard deviation but randomly add or subtract\n",
    "            noise = signs * np.random.normal(0, noise_factor * std_dev, size=len(group))\n",
    "            \n",
    "            # Apply noise\n",
    "            group_noisy[col] += noise\n",
    "        \n",
    "        noisy_dfs.append(group_noisy)\n",
    "    \n",
    "    return pd.concat(noisy_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_boolean_noise(data, columns, flip_prob=0.05):\n",
    "    \"\"\"\n",
    "    Flip boolean values in specified columns with a fixed probability.\n",
    "    \"\"\"\n",
    "    noisy_data = data.copy()\n",
    "    for col in columns:\n",
    "        mask = np.random.rand(len(data)) < flip_prob\n",
    "        noisy_data.loc[mask, col] = ~noisy_data.loc[mask, col]\n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_based_augmentation(df, copies, diagnosis_col, numeric_cols, bool_cols, flip_prob=0.05):\n",
    "    \"\"\"\n",
    "    Create multiple copies of the data, each with instance-based noise added.\n",
    "    \"\"\"\n",
    "    augmented_list = []\n",
    "    for i in range(copies):\n",
    "        # For each copy, add numeric and boolean noise.\n",
    "        noisy_numeric = add_numeric_noise_by_group(df, diagnosis_col, numeric_cols)\n",
    "        noisy_full = add_boolean_noise(noisy_numeric, bool_cols, flip_prob=flip_prob)\n",
    "        noisy_full[\"copy_id\"] = i  # (Optional) add an identifier for the copy\n",
    "        augmented_list.append(noisy_full)\n",
    "    return pd.concat(augmented_list, ignore_index=True)\n",
    "\n",
    "numeric_columns = [\"age\", \"TSH\", \"T3\", \"TT4\", \"T4U\", \"FTI\"]\n",
    "\n",
    "bool_columns = [\n",
    "    \"on_thyroxine\", \"query_on_thyroxine\", \"on_antithyroid_meds\", \"sick\", \n",
    "    \"pregnant\", \"thyroid_surgery\", \"I131_treatment\", \"query_hypothyroid\", \n",
    "    \"query_hyperthyroid\", \"lithium\", \"goitre\", \"tumor\", \"hypopituitary\", \"psych\"\n",
    "]\n",
    "\n",
    "for col in bool_columns:\n",
    "    df[col] = df[col].map({\"t\": True, \"f\": False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, numeric_cols):\n",
    "    \"\"\"\n",
    "    Cleans the dataset by:\n",
    "    - Removing outliers in numeric features\n",
    "    - Handling NaN values\n",
    "    - Ensuring logical consistency\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define valid ranges based on domain knowledge\n",
    "    valid_ranges = {\n",
    "        \"age\": (0, 120),\n",
    "        \"TSH\": (0.01, 10),\n",
    "        \"T3\": (0.5, 5),\n",
    "        \"TT4\": (50, 200),\n",
    "        \"T4U\": (0.5, 2),\n",
    "        \"FTI\": (40, 150),\n",
    "    }\n",
    "\n",
    "    # Clip numeric values within valid ranges\n",
    "    for col in numeric_cols:\n",
    "        if col in valid_ranges:\n",
    "            df[col] = np.clip(df[col], valid_ranges[col][0], valid_ranges[col][1])\n",
    "\n",
    "    # Drop rows where critical values are missing\n",
    "    df = df.dropna(subset=[\"age\", \"TSH\", \"T3\", \"TT4\"])  # Add other critical columns as needed\n",
    "\n",
    "    # Ensure logical consistency (Example: Pregnancy & Sex)\n",
    "    df.loc[df[\"pregnant\"] == True, \"sex\"] = \"F\"  # Pregnant patients must be female\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply cleaning BEFORE augmentation\n",
    "df_cleaned = clean_data(df, numeric_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance-based augmentation done, shape: (91720, 32)\n"
     ]
    }
   ],
   "source": [
    "df_augmented = instance_based_augmentation(df, copies=10, diagnosis_col=\"target\",\n",
    "                                           numeric_cols=numeric_columns,\n",
    "                                           bool_cols=bool_columns,\n",
    "                                           flip_prob=0.05)\n",
    "print(\"Instance-based augmentation done, shape:\", df_augmented.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_boolean_proportions(aug_df, orig_df, bool_cols):\n",
    "    \"\"\"\n",
    "    Adjust each boolean column in the augmented dataframe to have the same global\n",
    "    proportion of True values as in the original dataset.\n",
    "    \"\"\"\n",
    "    adj_df = aug_df.copy()\n",
    "    n_total = len(adj_df)\n",
    "    for col in bool_cols:\n",
    "        # Compute original and augmented proportions\n",
    "        orig_prop = orig_df[col].mean()  # Since booleans are 0/1, mean equals proportion of True\n",
    "        current_prop = adj_df[col].mean()\n",
    "        desired_count = int(round(orig_prop * n_total))\n",
    "        current_count = int(adj_df[col].sum())\n",
    "        difference = desired_count - current_count\n",
    "\n",
    "        # If we need to add True values:\n",
    "        if difference > 0:\n",
    "            # Identify indices where the value is False; randomly choose some to flip to True.\n",
    "            false_indices = adj_df.index[~adj_df[col]]\n",
    "            if len(false_indices) >= difference:\n",
    "                indices_to_flip = np.random.choice(false_indices, size=difference, replace=False)\n",
    "                adj_df.loc[indices_to_flip, col] = True\n",
    "        # If we need to remove True values:\n",
    "        elif difference < 0:\n",
    "            true_indices = adj_df.index[adj_df[col]]\n",
    "            if len(true_indices) >= abs(difference):\n",
    "                indices_to_flip = np.random.choice(true_indices, size=abs(difference), replace=False)\n",
    "                adj_df.loc[indices_to_flip, col] = False\n",
    "    return adj_df\n",
    "\n",
    "# Adjust boolean proportions in the augmented dataset.\n",
    "# df_augmented_adjusted = adjust_boolean_proportions(df_augmented, df, bool_columns)\n",
    "# df_augmented_adjusted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_numeric_variance(aug_df, orig_df, numeric_cols):\n",
    "    \"\"\"\n",
    "    Adjust each numeric column in the augmented dataframe so that its global variance\n",
    "    matches that of the original dataset.\n",
    "    \"\"\"\n",
    "    adj_df = aug_df.copy()\n",
    "    for col in numeric_cols:\n",
    "        orig_mean = orig_df[col].mean()\n",
    "        orig_var = orig_df[col].var()\n",
    "        aug_mean = adj_df[col].mean()\n",
    "        aug_var = adj_df[col].var()\n",
    "        if aug_var > 0:\n",
    "            scale = np.sqrt(orig_var / aug_var)\n",
    "            # Adjust augmented values while keeping the overall mean anchored at orig_mean.\n",
    "            adj_df[col] = orig_mean + (adj_df[col] - aug_mean) * scale\n",
    "        else:\n",
    "            print(f\"Warning: Zero variance in augmented column {col}\")\n",
    "    return adj_df\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# df_numeric_noisy = adjust_numeric_variance(df_augmented, df, numeric_columns)\n",
    "# df_numeric_noisy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, adjust boolean proportions\n",
    "df_augmented_adjusted = adjust_boolean_proportions(df_augmented, df, bool_columns)\n",
    "\n",
    "# Then, adjust numeric variance on the already adjusted dataset\n",
    "df_final_augmented = adjust_numeric_variance(df_augmented_adjusted, df, numeric_columns)\n",
    "\n",
    "# Save to CSV\n",
    "df_final_augmented.to_csv(\"aug3.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
